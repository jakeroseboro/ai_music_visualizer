{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-26T04:18:29.097795Z",
     "start_time": "2025-04-26T04:18:27.768045Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# üõ† Install everything\n",
    "!pip install moderngl diffusers transformers accelerate safetensors huggingface_hub moviepy imageio pillow soundfile --quiet"
   ],
   "id": "e1eed73cab4f40b3",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "raw",
   "source": "",
   "id": "97374500a7046c26",
   "outputs": null,
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# üñ•Ô∏è Base imports\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import moderngl\n",
    "\n",
    "from PIL import Image\n",
    "from diffusers import StableDiffusionPipeline\n",
    "from moviepy import VideoFileClip, AudioFileClip"
   ],
   "id": "e6ccdc21d0a6fcc6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# üé® Scene Generator\n",
    "class SceneGenerator:\n",
    "    def __init__(self, prompts, output_folder=\"generated_scenes\"):\n",
    "        self.prompts = prompts\n",
    "        self.output_folder = output_folder\n",
    "        os.makedirs(output_folder, exist_ok=True)\n",
    "        model_id = \"CompVis/stable-diffusion-v1-4\"\n",
    "        self.pipe = StableDiffusionPipeline.from_pretrained(model_id, torch_dtype=torch.float32)\n",
    "        self.pipe.to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    def generate(self):\n",
    "        scene_paths = []\n",
    "        for idx, prompt in enumerate(self.prompts):\n",
    "            output_path = os.path.join(self.output_folder, f\"scene_{idx}.png\")\n",
    "            if not os.path.exists(output_path):\n",
    "                print(f\"üé® Generating scene {idx+1}: {prompt}\")\n",
    "                image = self.pipe(prompt).images[0]\n",
    "                image.save(output_path)\n",
    "            scene_paths.append(output_path)\n",
    "        return scene_paths"
   ],
   "id": "2945b3198f3e99dc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# üé≠ Scene Fader\n",
    "class SceneFader:\n",
    "    def __init__(self, ctx, scene_paths):\n",
    "        self.ctx = ctx\n",
    "        self.textures = [self.load_texture(p) for p in scene_paths]\n",
    "        self.current = 0\n",
    "        self.next = 1\n",
    "        self.transition = 0.0\n",
    "\n",
    "    def load_texture(self, path):\n",
    "        img = Image.open(path).convert('RGB')\n",
    "        tex = self.ctx.texture(img.size, 3, img.tobytes())\n",
    "        tex.build_mipmaps()\n",
    "        return tex\n",
    "\n",
    "    def update(self, dt):\n",
    "        self.transition += dt * 0.05\n",
    "        if self.transition >= 1.0:\n",
    "            self.transition = 0.0\n",
    "            self.current = self.next\n",
    "            self.next = (self.next + 1) % len(self.textures)\n",
    "\n",
    "    def bind(self, prog):\n",
    "        self.textures[self.current].use(location=0)\n",
    "        if len(self.textures) > 1:\n",
    "            self.textures[self.next].use(location=1)\n",
    "        prog['mix_factor'].value = self.transition\n"
   ],
   "id": "aec52f3b6781234f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# üéµ Kick Detection\n",
    "def detect_kick(fft_chunk):\n",
    "    low = np.mean(fft_chunk[0:15])\n",
    "    mids = np.mean(fft_chunk[15:40])\n",
    "    return low > 5000 and mids < 1000\n"
   ],
   "id": "d310892e5adc71ea"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# üßπ Shader Loader\n",
    "def load_shader(shader_name):\n",
    "    with open(f\"shaders/common.vert\") as f:\n",
    "        vertex = f.read()\n",
    "    with open(f\"shaders/{shader_name}.frag\") as f:\n",
    "        fragment = f.read()\n",
    "    return vertex, fragment\n"
   ],
   "id": "243bff721a563730"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# üìÅ Make sure shaders are available (clone repo if missing)\n",
    "if not os.path.exists(\"shaders\"):\n",
    "    print(\"üîª Downloading shaders from GitHub...\")\n",
    "    !git clone https://github.com/jakeroseboro/ai_music_visualizer.git temp_repo\n",
    "    !mv temp_repo/shaders ./shaders\n",
    "    !rm -rf temp_repo\n",
    "    print(\"‚úÖ Shaders ready!\")"
   ],
   "id": "225ddd6e75a96409"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# üéµ Upload audio\n",
    "from google.colab import files\n",
    "print(\"üéµ Please upload your .wav or .mp3 file...\")\n",
    "uploaded = files.upload()\n",
    "audio_path = next(iter(uploaded.keys()))\n",
    "print(f\"‚úÖ Uploaded: {audio_path}\")\n"
   ],
   "id": "725520e1913102f0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# ‚úèÔ∏è Ask for shader and prompts\n",
    "shader_choice = input(\"üåÄ Choose shader style (fractal_blob / tunnel_wave / grid_glitch / storm_warp): \").strip()\n",
    "prompts = input(\"üñºÔ∏è Enter comma-separated AI prompts for scenes (ex: 'psychedelic mushrooms, cosmic desert'): \").strip()\n",
    "prompts = [p.strip() for p in prompts.split(\",\")]\n"
   ],
   "id": "e89d06c92e7563e0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# üöÄ Main rendering (COLAB mode)\n",
    "WIDTH, HEIGHT = 1280, 720\n",
    "FPS = 30\n",
    "\n",
    "ctx = moderngl.create_standalone_context()\n",
    "ctx.viewport = (0, 0, WIDTH, HEIGHT)\n",
    "\n",
    "vertex_shader, fragment_shader = load_shader(shader_choice)\n",
    "prog = ctx.program(vertex_shader=vertex_shader, fragment_shader=fragment_shader)\n",
    "\n",
    "vertices = np.array([\n",
    "    -1, -1,  0, 0,\n",
    "     1, -1,  1, 0,\n",
    "    -1,  1,  0, 1,\n",
    "    -1,  1,  0, 1,\n",
    "     1, -1,  1, 0,\n",
    "     1,  1,  1, 1\n",
    "], dtype='f4')\n",
    "vbo = ctx.buffer(vertices.tobytes())\n",
    "vao = ctx.simple_vertex_array(prog, vbo, 'in_vert', 'in_uv')\n",
    "\n",
    "# üé¨ Generate AI scenes\n",
    "scene_gen = SceneGenerator(prompts)\n",
    "scene_paths = scene_gen.generate()\n",
    "\n",
    "# üéµ Read Audio manually (no pygame.mixer!)\n",
    "import soundfile as sf\n",
    "audio_array, samplerate = sf.read(audio_path)\n",
    "if len(audio_array.shape) > 1:  # Stereo to mono\n",
    "    audio_array = audio_array.mean(axis=1)\n",
    "audio_array = (audio_array * 32767).astype(np.int16)\n",
    "audio_pos = 0\n",
    "chunk_size = 1024\n",
    "\n",
    "fader = SceneFader(ctx, scene_paths)\n",
    "\n",
    "time_val = 0.0\n",
    "frames = []\n",
    "samples_per_frame = int(samplerate / FPS)\n",
    "\n",
    "# üï∞Ô∏è Total frames based on audio length\n",
    "total_frames = len(audio_array) // samples_per_frame\n",
    "\n",
    "for _ in range(total_frames):\n",
    "    # Analyze audio chunk\n",
    "    if audio_pos + chunk_size < len(audio_array):\n",
    "        chunk = audio_array[audio_pos:audio_pos+chunk_size]\n",
    "        fft = np.abs(np.fft.fft(chunk)[:chunk_size // 2])\n",
    "        bass = np.mean(fft[0:20]) / 5000.0\n",
    "        kick = 1.0 if detect_kick(fft) else 0.0\n",
    "        audio_pos += samples_per_frame\n",
    "    else:\n",
    "        bass, kick = 0.0, 0.0\n",
    "\n",
    "    # Update AI scene transitions\n",
    "    fader.update(1.0 / FPS)\n",
    "\n",
    "    # Update shader uniforms\n",
    "    if 'iTime' in prog:\n",
    "        prog['iTime'].value = time_val\n",
    "    if 'iResolution' in prog:\n",
    "        prog['iResolution'].value = (WIDTH, HEIGHT)\n",
    "    if 'iBass' in prog:\n",
    "        prog['iBass'].value = bass\n",
    "    if 'kick' in prog:\n",
    "        prog['kick'].value = kick\n",
    "    if 'mix_factor' in prog:\n",
    "        fader.bind(prog)\n",
    "\n",
    "    ctx.clear()\n",
    "    vao.render()\n",
    "\n",
    "    frame = ctx.screen.read(components=3, alignment=1)\n",
    "    frames.append(frame)\n",
    "\n",
    "    time_val += 1.0 / FPS\n",
    "\n",
    "# üìπ Save to MP4\n",
    "import imageio\n",
    "writer = imageio.get_writer('output_video.mp4', fps=FPS)\n",
    "for frame in frames:\n",
    "    img = np.frombuffer(frame, dtype=np.uint8).reshape((HEIGHT, WIDTH, 3))\n",
    "    writer.append_data(img)\n",
    "writer.close()\n",
    "\n",
    "# üîä Merge with Audio\n",
    "video_clip = VideoFileClip(\"output_video.mp4\")\n",
    "audio_clip = AudioFileClip(audio_path)\n",
    "final_clip = video_clip.set_audio(audio_clip)\n",
    "final_clip.write_videofile(\"final_output.mp4\", codec='libx264')\n",
    "\n",
    "print(\"‚úÖ Final output saved: final_output.mp4\")"
   ],
   "id": "40e7138420e7667e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# üìπ Save final output\n",
    "writer = imageio.get_writer('output_video.mp4', fps=FPS)\n",
    "for frame in frames:\n",
    "    img = np.frombuffer(frame, dtype=np.uint8).reshape((HEIGHT, WIDTH, 3))\n",
    "    writer.append_data(img)\n",
    "writer.close()\n",
    "\n",
    "video_clip = VideoFileClip(\"output_video.mp4\")\n",
    "audio_clip = AudioFileClip(audio_path)\n",
    "final_clip = video_clip.set_audio(audio_clip)\n",
    "final_clip.write_videofile(\"final_output.mp4\", codec='libx264')\n",
    "\n",
    "print(\"‚úÖ Done! Final video: final_output.mp4\")\n"
   ],
   "id": "7c2f73fbce7ab3a7"
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
